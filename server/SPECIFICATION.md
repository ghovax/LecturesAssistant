# Lectures Assistant Architectural Specification

For non-technical users to "download and run," the entire application‚Äîbackend, frontend, and all dependencies‚Äîmust ship as a single executable. It must have an embedded SvelteKit front-end, an SQLite driver, and possibly the Whisper models, which are downloaded on the first run if necessary on-demand.

The server run on localhost port 3000 or the next available port. Configurable through the `configuration.yaml` file, of course.

## Storage Architecture

```
~/.lectures/                     # This is within the HOME folder
‚îú‚îÄ‚îÄ configuration.yaml                     # User settings, API keys
‚îú‚îÄ‚îÄ database.db                         # SQLite database
‚îú‚îÄ‚îÄ files/
‚îÇ   ‚îú‚îÄ‚îÄ lectures/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ {lecture_uuid}/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ media/                 # Multiple media files
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ 001-lecture-part1.mp4
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ 002-lecture-part2.mp4
‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ transcript/
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ combined.json       # Unified transcript from all media
‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ combined.vtt        # For video player sync
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ documents/              # Reference documents
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ {document_uuid}-slides.pdf
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ {document_uuid}-slides/
‚îÇ   ‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ 001.png
‚îÇ   ‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ 002.png
‚îÇ   ‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ {document_uuid}-notes.docx
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ exports/                        # Generated tools (guides, flashcards, etc.)
‚îÇ       ‚îî‚îÄ‚îÄ {tool_uuid}/
‚îÇ           ‚îú‚îÄ‚îÄ content.json
‚îÇ           ‚îî‚îÄ‚îÄ export.pdf
‚îî‚îÄ‚îÄ models/                         # Downloaded Whisper models on-demand
    ‚îî‚îÄ‚îÄ whisper-base.bin
```

## Data Model

This domain model represents the structure of an **AI-powered educational platform** that helps students turn lecture materials into study resources.

The hierarchy is organized by **academic context**: exams contain lectures, lectures contain media.

---

### 1. Organization: Exam ‚Üí Lecture Hierarchy

**Exam** is the root organizational entity.

- Represents a specific exam or course
- Contains one or more **Lectures**
- Chat sessions are scoped to an exam to prevent cross-subject contamination

**Lecture** is the container for a single lesson or session.

- Belongs to exactly one Exam
- Contains multiple **Media Files** (audio/video recordings) in a specified order
- Contains multiple **Reference Documents** (PDFs, PowerPoints, etc.)
- Generates a **Transcript** by combining all media files in order
- Acts as the "parent" for all associated materials

### 2. Core Content: Lecture Materials

Each Lecture can have:

- **Media Files** (1 or more): Audio or video recordings in a specified sequence. Transcripts are generated from all files combined in order.
- **Transcript:** Generated by combining transcripts from all media files (with time offset adjustments). Stored as unified segments with original media references.
- **Reference Documents** (0 or more): PDFs, PowerPoint files, or other documents. Each page/slide is extracted and indexed for AI analysis.

All of these are **children of the Lecture**‚Äîthey cannot exist independently.

### 3. Generated Outputs: Study Tools

Once the AI processes lecture materials, it creates:

- **Tool:** A structured document (study guide, flashcards, quiz, etc.) generated by an LLM. It cites its sources (transcripts or slides). The `type` field determines the output format.
- **ChatSession:** A workspace scoped to a specific Exam where students discuss the materials. Context can include any materials from lectures within that exam.

### 4. Configuration: How the AI Behaves

The system is flexible regarding which AI "brain" it uses:

- **LLMProvider:** Defines where the AI comes from (e.g., **OpenRouter** for cloud models or **Ollama** for local ones).
- **UserSettings:** A central place that remembers your preferences: preferred AI model, transcription service, language, and UI theme.

---

### Data Relationship Summary

| Entity                  | Purpose                                       | Hierarchy                                |
| ----------------------- | --------------------------------------------- | ---------------------------------------- |
| **Exam**                | Course/exam grouping                          | Root                                     |
| **Lecture**             | Single lesson or session                      | Child of Exam                            |
| **Media Files**         | Audio/video recordings (multiple, ordered)    | Children of Lecture                      |
| **Transcript**          | Unified text from all media files             | Child of Lecture                         |
| **Reference Documents** | PDFs, PowerPoints, etc. (multiple)            | Children of Lecture                      |
| **Tool**                | AI-generated content (guide, flashcard, quiz) | References Lectures within same Exam     |
| **ChatSession**         | Interactive Q&A                               | Scoped to one Exam                       |
| **ChatMessage**         | Individual message in a session               | Child of ChatSession, includes citations |

```json
TranscriptSegment {
    start_millisecond: number      // Milliseconds from start
    end_millisecond: number
    text: string
    confidence: number    // 0-1
    speaker?: string      // Future: speaker diarization
}
```

```json
ToolContent {
    type: "guide" | "flashcard" | "quiz" | "custom"
    sections: [
        {
            title: string
            content: string (markdown)
            source_refs: [
                { type: "transcript", source_id, segment_range: [start_index, end_index] }
                { type: "slide", source_id, page_number }
                { type: "tool", source_id }
            ]
        }
    ]
    metadata: {
        generated_at: timestamp
        model_used: string
        prompt_template: string
    }
}
```

---

## üóÑÔ∏è Database Schema

The system uses SQLite for all persistent storage. Below is the complete schema with foreign key relationships.

```sql
-- Root: Exams
CREATE TABLE exams (
    id TEXT PRIMARY KEY,
    title TEXT NOT NULL,
    description TEXT,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- Lectures belong to Exams
CREATE TABLE lectures (
    id TEXT PRIMARY KEY,
    exam_id TEXT NOT NULL REFERENCES exams(id) ON DELETE CASCADE,
    title TEXT NOT NULL,
    description TEXT,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- Media Files: Audio/Video recordings (one or more per lecture, ordered)
CREATE TABLE lecture_media (
    id TEXT PRIMARY KEY,
    lecture_id TEXT NOT NULL REFERENCES lectures(id) ON DELETE CASCADE,
    media_type TEXT CHECK(media_type IN ('audio', 'video')) NOT NULL,
    sequence_order INTEGER NOT NULL,        -- Order in which to process (for transcript combining)
    duration_milliseconds INTEGER,
    file_path TEXT NOT NULL,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(lecture_id, sequence_order)      -- One file per sequence position
);

-- Unified Transcript (generated from combining all lecture_media files)
CREATE TABLE transcripts (
    id TEXT PRIMARY KEY,
    lecture_id TEXT NOT NULL UNIQUE REFERENCES lectures(id) ON DELETE CASCADE,
    language TEXT,
    status TEXT CHECK(status IN ('pending', 'processing', 'completed', 'failed')) DEFAULT 'pending',
    confidence REAL DEFAULT 0,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- Transcript segments with reference to original media file
CREATE TABLE transcript_segments (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    transcript_id TEXT NOT NULL REFERENCES transcripts(id) ON DELETE CASCADE,
    media_id TEXT REFERENCES lecture_media(id) ON DELETE SET NULL,
    start_millisecond INTEGER NOT NULL,    -- Time in combined transcript
    end_millisecond INTEGER NOT NULL,
    original_start_milliseconds INTEGER,             -- Original time in source media file
    original_end_milliseconds INTEGER,
    text TEXT NOT NULL,
    confidence REAL,
    speaker TEXT
);

-- Reference Documents: PDFs, PowerPoints, etc. (zero or more per lecture)
CREATE TABLE reference_documents (
    id TEXT PRIMARY KEY,
    lecture_id TEXT NOT NULL REFERENCES lectures(id) ON DELETE CASCADE,
    document_type TEXT CHECK(document_type IN ('pdf', 'pptx', 'docx', 'other')) NOT NULL,
    title TEXT NOT NULL,
    file_path TEXT NOT NULL,
    page_count INTEGER NOT NULL,
    extraction_status TEXT CHECK(extraction_status IN ('pending', 'processing', 'completed', 'failed')) DEFAULT 'pending',
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- Pages/Slides extracted from reference documents
CREATE TABLE reference_pages (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    document_id TEXT NOT NULL REFERENCES reference_documents(id) ON DELETE CASCADE,
    page_number INTEGER NOT NULL,
    image_path TEXT NOT NULL,
    extracted_text TEXT,
    UNIQUE(document_id, page_number)
);

-- Generated tools (study guides, flashcards, etc., scoped to Exam)
CREATE TABLE tools (
    id TEXT PRIMARY KEY,
    exam_id TEXT NOT NULL REFERENCES exams(id) ON DELETE CASCADE,
    type TEXT CHECK(type IN ('guide', 'flashcard', 'quiz', 'custom')) NOT NULL,
    title TEXT NOT NULL,
    content JSON NOT NULL,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE tool_source_refs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    tool_id TEXT NOT NULL REFERENCES tools(id) ON DELETE CASCADE,
    source_type TEXT CHECK(source_type IN ('transcript', 'document')) NOT NULL,
    source_id TEXT NOT NULL,
    metadata JSON                      -- e.g., { segment_range: [5, 12], media_file_id: "..." }
);

-- Chat sessions (scoped to an Exam)
CREATE TABLE chat_sessions (
    id TEXT PRIMARY KEY,
    exam_id TEXT NOT NULL REFERENCES exams(id) ON DELETE CASCADE,
    title TEXT,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE chat_messages (
    id TEXT PRIMARY KEY,
    session_id TEXT NOT NULL REFERENCES chat_sessions(id) ON DELETE CASCADE,
    role TEXT CHECK(role IN ('user', 'assistant', 'system')) NOT NULL,
    content TEXT NOT NULL,
    model_used TEXT,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE chat_citations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    message_id TEXT NOT NULL REFERENCES chat_messages(id) ON DELETE CASCADE,
    source_type TEXT CHECK(source_type IN ('transcript', 'slide', 'tool')) NOT NULL,
    source_id TEXT NOT NULL,
    location_type TEXT CHECK(location_type IN ('segment_range', 'page', 'section')),
    location_data JSON,
    snippet TEXT NOT NULL
);

-- Chat context: which lectures' materials to include in the session
CREATE TABLE chat_context_configuration (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    session_id TEXT NOT NULL UNIQUE REFERENCES chat_sessions(id) ON DELETE CASCADE,
    included_lecture_ids JSON,  -- Array of lecture UUIDs (must belong to same exam)
                                -- When a lecture is included, ALL its media files, transcript, and documents are available
    included_tool_ids JSON      -- Array of tool UUIDs (must reference lectures in same exam)
);

-- Background jobs
CREATE TABLE jobs (
    id TEXT PRIMARY KEY,
    type TEXT CHECK(type IN ('TRANSCRIBE_MEDIA', 'INGEST_DOCUMENTS', 'BUILD_MATERIAL', 'PUBLISH_MATERIAL')) NOT NULL,
    status TEXT CHECK(status IN ('PENDING', 'RUNNING', 'COMPLETED', 'FAILED', 'CANCELLED')) DEFAULT 'PENDING',
    progress INTEGER DEFAULT 0,
    progress_message_text TEXT,
    payload JSON NOT NULL,
    result JSON,
    error TEXT,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    started_at DATETIME,
    completed_at DATETIME
);

-- User settings
CREATE TABLE settings (
    key TEXT PRIMARY KEY,
    value JSON NOT NULL,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

### Key Design Decisions

1. **Exam Hierarchy:** Exams are the root organizational unit. All lectures belong to exactly one exam. This prevents cross-subject contamination in chat sessions and tools.

2. **Multiple Media Files:** Each lecture can have many audio/video files in a specified sequence order. This allows users to upload recordings from different parts of a single session.

3. **Unified Transcript:** Transcripts are generated by combining all media files in sequence order. Each segment tracks which media file it came from. Time offsets are adjusted to match the combined transcript.

4. **Reference Documents:** Each lecture can have multiple reference documents (PDFs, PowerPoints, Word docs). Each document is extracted into pages and indexed independently.

5. **Media Ordering:** `sequence_order` enforces a specific playback/processing order. Reordering updates the transcript regeneration job.

6. **Chat Scoping:** Chat sessions are always scoped to an exam. When a lecture is selected for context, ALL its materials (all media files, transcript, all reference documents) are included.

7. **Tools Scoped:** Study tools belong to an exam and reference only sources from lectures in that exam.

8. **Citations:** Track which media file a transcript segment came from, and which document a reference came from. This enables linking AI responses back to sources.

9. **Flexible Document Types:** Support PDF, PowerPoint, Word, and other formats. Extraction status tracked per document.

This is the complete API surface for your platform, organized by functional domain. All endpoints follow a RESTful structure, while heavy lifting and streaming are handled via Web Sockets.

---

## üìö EXAMS

_Course and exam management‚Äîthe root organizational unit._

| Method   | Endpoint         | Description                                                                             |
| -------- | ---------------- | --------------------------------------------------------------------------------------- |
| `POST`   | `/api/exams`     | Create a new exam.                                                                      |
| `GET`    | `/api/exams`     | List all exams.                                                                         |
| `GET`    | `/api/exams/:id` | Get exam metadata and summary of lectures.                                              |
| `PATCH`  | `/api/exams/:id` | Update exam title or description.                                                       |
| `DELETE` | `/api/exams/:id` | Delete exam and all associated lectures, transcripts, slides, tools, and chat sessions. |

---

## üèõÔ∏è LECTURES & CONTENT

_The ingestion layer for lectures and their associated media. All lectures belong to an exam._

| Method   | Endpoint                                                           | Description                                                             |
| -------- | ------------------------------------------------------------------ | ----------------------------------------------------------------------- |
| `POST`   | `/api/exams/:exam_id/lectures`                                     | Create a new lecture in an exam.                                        |
| `GET`    | `/api/exams/:exam_id/lectures`                                     | List all lectures in an exam.                                           |
| `GET`    | `/api/exams/:exam_id/lectures/:lecture_id`                         | Get lecture metadata and summary of media/documents.                    |
| `PATCH`  | `/api/exams/:exam_id/lectures/:lecture_id`                         | Update lecture title or description.                                    |
| `DELETE` | `/api/exams/:exam_id/lectures/:lecture_id`                         | Delete lecture and all child data (media, transcripts, documents).      |
| `POST`   | `/api/exams/:exam_id/lectures/:lecture_id/media/upload`            | Upload audio/video file (appended to lecture media list).               |
| `GET`    | `/api/exams/:exam_id/lectures/:lecture_id/media`                   | List all media files in sequence order.                                 |
| `PATCH`  | `/api/exams/:exam_id/lectures/:lecture_id/media/:media_id/reorder` | Change sequence order of a media file.                                  |
| `DELETE` | `/api/exams/:exam_id/lectures/:lecture_id/media/:media_id`         | Delete a specific media file (triggers transcript regeneration).        |
| `POST`   | `/api/exams/:exam_id/lectures/:lecture_id/transcribe`              | Trigger transcription job (combines all media files in sequence order). |
| `GET`    | `/api/exams/:exam_id/lectures/:lecture_id/transcript`              | Fetch the unified transcript segments.                                  |
| `GET`    | `/api/exams/:exam_id/lectures/:lecture_id/transcript/export`       | Download as `.srt`, `.vtt`, or `.txt`.                                  |

---

## üìÑ REFERENCE DOCUMENTS

_PDFs, PowerPoints, and other reference materials for a lecture. Multiple documents supported._

| Method   | Endpoint                                                                                   | Description                                            |
| -------- | ------------------------------------------------------------------------------------------ | ------------------------------------------------------ |
| `POST`   | `/api/exams/:exam_id/lectures/:lecture_id/documents/upload`                                | Upload a reference document (PDF, PPTX, DOCX, etc.).   |
| `GET`    | `/api/exams/:exam_id/lectures/:lecture_id/documents`                                       | List all reference documents for this lecture.         |
| `GET`    | `/api/exams/:exam_id/lectures/:lecture_id/documents/:document_id`                          | Get document metadata (page count, extraction status). |
| `DELETE` | `/api/exams/:exam_id/lectures/:lecture_id/documents/:document_id`                          | Delete a specific reference document.                  |
| `GET`    | `/api/exams/:exam_id/lectures/:lecture_id/documents/:document_id/pages`                    | List pages with their respective image URLs.           |
| `GET`    | `/api/exams/:exam_id/lectures/:lecture_id/documents/:document_id/pages/:page_number/image` | Serve the actual PNG/JPG for a specific page.          |
| `POST`   | `/api/exams/:exam_id/lectures/:lecture_id/documents/:document_id/extract`                  | Run AI OCR to extract text from pages.                 |

---

## üõ†Ô∏è TOOLS (Generative AI)

_Study tools (guides, flashcards, quizzes) generated from lecture materials within an exam._

| Method   | Endpoint                                    | Description                                                               |
| -------- | ------------------------------------------- | ------------------------------------------------------------------------- |
| `POST`   | `/api/exams/:exam_id/tools`                 | **Generate:** `{ "type": "guide", "sources": [...], "template": "..." }`. |
| `GET`    | `/api/exams/:exam_id/tools`                 | List all tools in exam (filter via `?type=guide`).                        |
| `GET`    | `/api/exams/:exam_id/tools/:tool_id`        | Retrieve the specific JSON content/markdown of a tool.                    |
| `PATCH`  | `/api/exams/:exam_id/tools/:tool_id`        | Manually edit or override AI-generated content.                           |
| `DELETE` | `/api/exams/:exam_id/tools/:tool_id`        | Remove a generated tool.                                                  |
| `GET`    | `/api/exams/:exam_id/tools/:tool_id/export` | Export the tool as PDF or Markdown file.                                  |

---

## üí¨ CHAT SESSIONS

_Interactive conversations scoped to an exam. Context can only include lectures from the exam._

| Method   | Endpoint                                                 | Description                                              |
| -------- | -------------------------------------------------------- | -------------------------------------------------------- |
| `POST`   | `/api/exams/:exam_id/chat/sessions`                      | Create a new chat session for this exam.                 |
| `GET`    | `/api/exams/:exam_id/chat/sessions`                      | List chat sessions in this exam.                         |
| `GET`    | `/api/exams/:exam_id/chat/sessions/:session_id`          | Fetch session history and current context configuration. |
| `PATCH`  | `/api/exams/:exam_id/chat/sessions/:session_id/context`  | Update which lectures' materials to include in context.  |
| `POST`   | `/api/exams/:exam_id/chat/sessions/:session_id/messages` | Send user message (triggers Web Socket stream).          |
| `DELETE` | `/api/exams/:exam_id/chat/sessions/:session_id`          | Delete session and all messages.                         |

---

## ‚öôÔ∏è SETTINGS & SYSTEM

_Global configuration, authentication, and environment health._

| Domain       | Method   | Endpoint                      | Description                                              |
| ------------ | -------- | ----------------------------- | -------------------------------------------------------- |
| **Auth**     | `POST`   | `/api/auth/setup`             | Set password on first startup (no auth required).        |
| **Auth**     | `POST`   | `/api/auth/login`             | Login with password, get session cookie or bearer token. |
| **Auth**     | `POST`   | `/api/auth/logout`            | Logout and invalidate session.                           |
| **Auth**     | `GET`    | `/api/auth/status`            | Check if authenticated and get current session info.     |
| **Settings** | `GET`    | `/api/settings`               | Get user preferences and provider keys.                  |
| **Settings** | `PATCH`  | `/api/settings`               | Update theme, model, or language.                        |
| **AI**       | `GET`    | `/api/settings/llm/providers` | List available backends (OpenRouter, Ollama).            |
| **AI**       | `POST`   | `/api/settings/llm/test`      | Validate API key/local connection.                       |
| **Jobs**     | `GET`    | `/api/jobs`                   | Monitor status of active transcriptions/extractions.     |
| **Jobs**     | `DELETE` | `/api/jobs/:id`               | Kill a running background process.                       |
| **System**   | `GET`    | `/api/health`                 | Check server and DB availability (no auth required).     |

---

## üîê API Standards & Error Handling

### Standard Success Response

All successful responses follow this structure:

```json
{
  "data": {
    /* resource or array of resources */
  },
  "meta": {
    "timestamp": "2024-02-05T12:34:56Z",
    "request_id": "req-abc123"
  }
}
```

### Standard Error Response

All error responses follow this structure:

```json
{
  "error": {
    "code": "ERROR_CODE",
    "message": "Human-readable error description",
    "details": {
      /* optional field-level errors */
    }
  },
  "meta": {
    "timestamp": "2024-02-05T12:34:56Z",
    "request_id": "req-abc123"
  }
}
```

### HTTP Status Codes

| Status            | Code             | Scenarios                                       |
| ----------------- | ---------------- | ----------------------------------------------- |
| 200 OK            | Success          | Standard successful request                     |
| 201 Created       | Resource created | POST that creates a resource                    |
| 400 Bad Request   | VALIDATION_ERROR | Invalid input, missing required fields          |
| 401 Unauthorized  | AUTH_ERROR       | Authentication required or failed (if enabled)  |
| 404 Not Found     | NOT_FOUND        | Resource does not exist                         |
| 409 Conflict      | CONFLICT         | Resource already exists, or job already running |
| 422 Unprocessable | INVALID_FORMAT   | File type not supported, PDF too large, etc.    |
| 503 Unavailable   | PROVIDER_ERROR   | LLM provider is down or unreachable             |

### Error Code Reference

```typescript
enum ErrorCode {
  VALIDATION_ERROR = "VALIDATION_ERROR",
  NOT_FOUND = "NOT_FOUND",
  ALREADY_EXISTS = "ALREADY_EXISTS",
  INVALID_FORMAT = "INVALID_FORMAT",
  FILE_TOO_LARGE = "FILE_TOO_LARGE",
  UNSUPPORTED_TYPE = "UNSUPPORTED_TYPE",
  PROVIDER_ERROR = "PROVIDER_ERROR",
  JOB_RUNNING = "JOB_RUNNING",
  CONTEXT_OVERFLOW = "CONTEXT_OVERFLOW",
  AUTH_ERROR = "AUTH_ERROR",
}
```

---

## üì§ File Upload Configuration

### Upload Constraints

```yaml
uploads:
  media:
    maximum_file_size_megabytes: 2048 # 2GB per media file
    maximum_files_per_lecture: 50 # Prevent excessive uploads
    supported_formats:
      video: [mp4, webm, mov, mkv]
      audio: [mp3, wav, m4a, ogg, flac]
    chunked_upload_threshold_megabytes: 100 # Use chunked for files > 100MB

  documents:
    maximum_file_size_megabytes: 500 # 500MB per document
    maximum_files_per_lecture: 100
    maximum_pages_per_document: 500 # Prevent excessive processing
    supported_formats: [pdf, pptx, docx]
```

### Upload Process

**For files < 100MB:**

```
POST /api/lectures/upload
Content-Type: multipart/form-data
Body: { file: <binary> }

Response:
{
    "data": {
        "lecture_id": "uuid",
        "status": "uploaded",
        "message": "File received. Transcription not started‚Äîuse POST /api/lectures/:id/transcribe"
    }
}
```

**For files >= 100MB (chunked):**

```
1. POST /api/lectures/upload/initialize
   Body: { filename, file_size_bytes }
   Response: { upload_id, chunk_size_bytes }

2. POST /api/lectures/upload/:upload_id/chunk?chunk_number=0
   Body: <binary chunk>

3. POST /api/lectures/upload/:upload_id/complete
   Response: { lecture_id, status }
```

---

## üí¨ Chat Message Structure

### Chat Message Object

```typescript
interface ChatMessage {
  id: string; // UUID
  session_id: string; // Parent session
  role: "user" | "assistant" | "system";
  content: string; // Markdown-formatted text

  // For assistant messages only
  model_used?: string; // e.g., "claude-3.5-sonnet"
  citations?: Citation[];

  created_at: string; // ISO 8601 timestamp
}

interface Citation {
  id: string;
  source_type: "transcript" | "document" | "tool";
  source_id: string;
  location: {
    type: "segment_range" | "page" | "section";

    // For transcript segments:
    segment_start_index?: number;
    segment_end_index?: number;
    media_file_id?: string; // Which media file this segment came from

    // For reference documents:
    page_number?: number;
    document_id?: string;

    // For tools:
    section_index?: number;
  };
  snippet: string; // The cited text (first 200 chars)
}
```

### Chat Session Context Configuration

```typescript
interface ChatContextConfiguration {
  session_id: string;
  included_lectures: string[]; // Lecture UUIDs
  included_slides: string[]; // SlideDocument UUIDs
  included_tools: string[]; // Tool UUIDs
}
```

---

## üß† Context Assembly Strategy

When you send a message to a chat session, the system must assemble the full context before sending to the LLM. Here's the strategy:

### 1. Token Budget Calculation

```
available_tokens = model_maximum_context - system_prompt_tokens - response_buffer
response_buffer = 2000  // Reserve for model response
```

### 2. Context Priority (if sources exceed budget)

If all selected sources exceed the available token budget:

1. **Keep all conversation history** (most recent messages first)
2. **Reserve 30% of available tokens** for conversation history
3. **Remaining 70%** for source material from selected lectures:
   - Include full content for all selected sources if possible
   - If sources exceed budget, use this priority order:
     1. **Transcript** - Include most recent segments first (respects media file sequence order)
     2. **Reference Documents** - Include in order uploaded
     3. **Generated Tools** - Include full content

### 3. Truncation Behavior

If a transcript segment or slide page exceeds available space:

```
- Truncate with "..." at the end
- Include a notice: "[Content truncated due to context limits]"
- Never truncate in the middle of a sentence if possible
```

### 4. Error on Overflow

If even after truncation the context exceeds budget:

```json
{
  "error": {
    "code": "CONTEXT_OVERFLOW",
    "message": "Selected sources exceed model context limit. Remove or summarize sources.",
    "details": {
      "available_tokens": 90000,
      "required_tokens": 125000,
      "suggestion": "Remove 1-2 slide documents or older transcripts"
    }
  }
}
```

### 5. Truncation Strategy

If sources exceed the available token budget after priority ordering, truncate longer content and include a notice to the user. This keeps the implementation straightforward while still providing useful context.

---

## üîå WEB SOCKET PROTOCOL

_Proper Web Socket communication for asynchronous updates._

### Connection & Handshake

```typescript
// Client initiates connection
WebSocket URL: ws://localhost:3000/api/ws

// Server responds with handshake
{
    "type": "connected",
    "timestamp": "2024-02-05T12:34:56Z",
    "server_version": "1.0.0"
}
```

### Message Envelope Format

All WebSocket messages (client ‚Üí server and server ‚Üí client) follow this envelope:

```typescript
interface WSMessage {
  type: string; // e.g., "subscribe", "job:progress", "chat:token"
  channel: string; // e.g., "job:abc123", "chat:xyz789"
  payload: any; // Message-specific data
  timestamp: string; // ISO 8601 timestamp
  sequence: number; // Monotonically increasing per channel
}
```

### Client ‚Üí Server: Subscribe/Unsubscribe

```typescript
interface WSSubscribe {
  type: "subscribe" | "unsubscribe";
  channel: string; // Channel identifier
  timestamp: string;
}
```

### Server ‚Üí Client: Channel Management

```typescript
// Subscription confirmed, optionally with current state
{
    "type": "subscribed",
    "channel": "job:abc123",
    "timestamp": "2024-02-05T12:34:56Z",
    "current_state": {          // Optional: current job state
        "status": "RUNNING",
        "progress": 45,
        "progress_message_text": "Processing Page 5/12..."
    }
}

// Subscription failed
{
    "type": "error",
    "channel": "chat:invalid",
    "payload": {
        "code": "INVALID_CHANNEL",
        "message": "Channel does not exist or access denied"
    },
    "timestamp": "2024-02-05T12:34:56Z"
}
```

### Keepalive & Heartbeat

The server sends a heartbeat every 30 seconds on active channels:

```typescript
{
    "type": "heartbeat",
    "channel": "job:abc123",
    "timestamp": "2024-02-05T12:34:56Z"
}
```

Client should respond with pong within 5 seconds. If no heartbeat is received after 60 seconds, client may reconnect.

### Channel Types

#### 1. Background Jobs (`job:<id>`)

**Subscribe to monitor a job:**

```
Client: { "type": "subscribe", "channel": "job:abc123" }

Server updates:
{
    "type": "job:progress",
    "channel": "job:abc123",
    "payload": {
        "status": "RUNNING",
        "progress": 45,
        "progress_message_text": "Extracting text from page 5 of 12..."
    },
    "timestamp": "2024-02-05T12:34:56Z",
    "sequence": 1
}

{
    "type": "job:complete",
    "channel": "job:abc123",
    "payload": {
        "status": "COMPLETED",
        "result": {
            "transcript_id": "uuid",
            "duration_milliseconds": 3600000,
            "segment_count": 240
        }
    },
    "timestamp": "2024-02-05T12:35:12Z",
    "sequence": 2
}

// Or on failure:
{
    "type": "job:failed",
    "channel": "job:abc123",
    "payload": {
        "status": "FAILED",
        "error": "Whisper model download failed: insufficient disk space"
    },
    "timestamp": "2024-02-05T12:35:12Z",
    "sequence": 2
}
```

#### 2. Real-time Chat (`chat:<session_id>`)

**Subscribe to receive streaming messages:**

```
Client: { "type": "subscribe", "channel": "chat:xyz789" }

Server streams the assistant's response as it generates:
{
    "type": "chat:token",
    "channel": "chat:xyz789",
    "payload": {
        "token": "The",
        "accumulated_text": "The"
    },
    "timestamp": "2024-02-05T12:34:57Z",
    "sequence": 1
}

{
    "type": "chat:token",
    "channel": "chat:xyz789",
    "payload": {
        "token": " main",
        "accumulated_text": "The main"
    },
    "timestamp": "2024-02-05T12:34:57Z",
    "sequence": 2
}

// Final message with complete structure
{
    "type": "chat:complete",
    "channel": "chat:xyz789",
    "payload": {
        "message_id": "msg-123",
        "role": "assistant",
        "content": "The main topics covered were...",
        "model_used": "claude-3.5-sonnet",
        "citations": [
            {
                "id": "cite-1",
                "source_type": "transcript",
                "source_id": "uuid",
                "location": {
                    "type": "segment_range",
                    "segment_start_index": 5,
                    "segment_end_index": 12
                },
                "snippet": "The main topics were..."
            }
        ]
    },
    "timestamp": "2024-02-05T12:34:59Z",
    "sequence": 10
}
```

### Reconnection & State Recovery

If a client disconnects and reconnects:

1. **Connection is re-established** with the server
2. **Client resubscribes** to channels: `{ "type": "subscribe", "channel": "job:abc123" }`
3. **Server sends current state** in the `subscribed` message
4. **Client resumes** from the last known `sequence` number (server can replay missed messages if within buffer)

### Backpressure & Flow Control

If the client can't keep up with messages:

- Server buffers up to 100 messages per channel
- If buffer exceeds limit, server closes channel with `type: "dropped"`
- Client should reconnect and catch up from current state

---

## üß† The LLM Capability Matrix

The system uses a **Capability-First** approach. Before executing a command, the orchestrator checks the model's "passport" to ensure it can handle the specific task.

---

## üß† The LLM Capability Matrix

The system uses a **Capability-First** approach. Before executing a command, the orchestrator checks the model's "passport" to ensure it can handle the specific task.

| Operation                 | Required Capability | Implementation Logic                                                           |
| ------------------------- | ------------------- | ------------------------------------------------------------------------------ |
| **Chat / Study Guides**   | `text_generation`   | Standard prompt/response or streaming.                                         |
| **Slide Text Extraction** | `vision`            | Requires `ContentPart` with `image` data and OCR-optimized prompts.            |
| **Context Management**    | `maximum_context`   | Ensures the model's "memory" can hold the requested lecture/transcript length. |

---

## üíª Technical Interface Definitions

### 1. The LLM Provider Contract

This interface ensures that whether you use a cloud-based API (OpenRouter) or a local instance (Ollama), the application code remains identical.

```typescript
interface LLMProvider {
  id: string; // e.g., "openrouter", "ollama"
  name: string; // Display name

  // Lifecycle & Config
  configure(config: ProviderConfig): void;
  validate(): Promise<ValidationResult>; // Tests API keys/connectivity

  // Discovery
  listModels(): Promise<Model[]>;
  getModelCapabilities(model: string): Capabilities;

  // Execution
  chat(request: ChatRequest): AsyncStream<ChatChunk>;

  // Vision (Optional)
  analyzeImage?(image: Base64, prompt: string): AsyncStream<ChatChunk>;
}
```

### 2. Message & Content Structure

The system supports **Multimodal** inputs. A message isn't just a string; it‚Äôs an array of `ContentPart` objects.

- **Role:** `user`, `assistant`, or `system`.
- **ContentPart:** Can be `type: "text"` or `type: "image"`.
- **Image Handling:** Stores `Base64` data and specifies the media type (`image/png` or `image/jpeg`).

---

## üóÉÔ∏è The Provider Registry

This is a **Singleton** service that manages the lifecycle of all AI backends. It acts as the "Source of Truth" for the application.

- **`register(provider)`:** Injects a new service (like a Whisper wrapper or GPT-4o).
- **`getActive()`:** Retrieves the provider currently selected in `UserSettings`.
- **`getProviderForCapability(cap)`:** The logic-gate that prevents you from trying to "see" a slide image with a text-only model.

---

## üéôÔ∏è Transcription & Audio Processing

Decoupled from the LLM logic, this interface focuses on converting heavy binary audio into timestamped JSON.

### **The TranscriptionProvider**

- **`AudioSource`:** Tracks the local file path, format, and total duration.
- **`TranscriptionOptions`:** Controls language detection and whether to generate `word_timestamps` (critical for clicking a transcript line to play that moment in the video).
- **`onProgress` Callback:** A vital hook that sends real-time percentages to the **Web Socket** `job:progress` channel.

---

## üîÑ How it all ties together

When you ask for a **Study Guide** via the **Tools API**:

1. **Registry** finds the active provider.
2. **App** confirms the model has `text_generation`.
3. **App** sends a `ChatRequest` containing the `system_prompt` (Guide template) and the `messages` (the lecture transcript text).
4. **Provider** returns an `AsyncStream`, which the server pipes directly to your **Web Socket** so the guide appears to "write itself" in real-time.

---

This module defines the **Asynchronous Core** of the application. Because processing PDFs and transcribing audio are time-intensive, the system uses a robust pipeline and state machine to ensure the user interface remains snappy while the heavy lifting happens in the background.

---

## üìÑ PDF Processing Pipeline

Instead of just "reading" a PDF, the system treats each slide as a high-fidelity visual asset. This ensures that diagrams, formulas, and complex layouts are preserved for the AI to analyze.

### **The Workflow**

1. **Validation:** Checks for file integrity and limits (e.g., page count or file size).
2. **Image Rendering:** Converts each page into a **150 DPI PNG**. This allows the UI to display slides instantly without requiring a PDF viewer.
3. **Metadata Storage:** Creates the `SlideDocument` record. At this stage, the slides are viewable but not yet "searchable."
4. **Vision LLM Extraction:** The "Intelligence" step. The system sends each page image to a Vision-capable LLM with a specific prompt to extract text, preserving the context of where words appear relative to images.

---

## üèóÔ∏è Job Queue Architecture

To manage these long-running tasks, the system uses a **Job Queue**. This prevents the server from timing out during a 2-hour transcription or a 50-page PDF extraction.

### **Job Types**

The system categorizes background work into specific types, each with its own input (`payload`) and output (`result`):

- `TRANSCRIBE_MEDIA`: Audio/Video ‚Üí JSON Transcript.
- `INGEST_DOCUMENTS`: PDF ‚Üí Images ‚Üí Structured Text.
- `BUILD_MATERIAL`: Sources ‚Üí Study Tool (using the `guide` parameter).
- `PUBLISH_MATERIAL`: Tool JSON ‚Üí PDF/Markdown file.

---

## üîÑ Job State Machine

Every job follows a strict lifecycle. This state is synchronized to the frontend via the **Web Socket** `job:progress` channel.

| State         | Transition Trigger               | UI Behavior                                  |
| ------------- | -------------------------------- | -------------------------------------------- |
| **PENDING**   | Job created, waiting for worker. | "In Queue..."                                |
| **RUNNING**   | Worker picks up the task.        | Show progress bar & `progress_message_text`. |
| **COMPLETED** | Task finished successfully.      | Green check; data becomes available.         |
| **FAILED**    | Error caught during execution.   | Red alert; show `error` string.              |
| **CANCELLED** | User manually stops the job.     | Remove from active list.                     |

---

## üìä The Job Record (Data Model)

Each job is a persistent record in the database, allowing users to refresh the page without losing track of their progress.

```typescript
interface Job {
  id: UUID;
  type: JobType;
  status: JobStatus;
  progress: number; // 0-100%
  progress_message_text: string; // e.g., "Processing Page 4/12..."

  payload: JSON; // Input (e.g., { lecture_id: "..." })
  result?: JSON; // Output (e.g., { transcript_id: "..." })
  error?: string; // Failure details

  timing: {
    created_at: Date;
    started_at?: Date;
    completed_at?: Date;
  };
}
```

### **Why this matters for the User**

By storing the `progress_message_text` and `progress` percentage, the **Web Socket** can push updates like:

> _"Extracting text from Slide 12..." (85%)_

This provides a high-end, responsive feel even when the backend is performing complex AI operations.

## Settings Schema

```yaml
# configuration.yaml - User settings file

llm:
  provider: openrouter # or "ollama"

  openrouter:
    api_key: "sk-or-..."
    default_model: "anthropic/claude-3.5-sonnet"

  ollama:
    base_url: "http://localhost:11434"
    default_model: "llama3.2"

transcription:
  provider: whisper-local # or "openai-api"

  whisper:
    model: base # tiny, base, small, medium, large
    device: auto # auto, cpu, cuda

  openai:
    api_key: "sk-..." # Optional: use separate key

documents:
  render_dots_per_inch: 150 # Resolution for rendering document pages to images
  maximum_pages: 500 # maximum pages per document
  supported_formats: [pdf, pptx, docx]

storage:
  data_directory: ~/.lectures # Override default location

server:
  port: 3000
  host: 127.0.0.1 # localhost by default
```

---

## üîê Authentication & Security

The application uses **session-based authentication** with password-protected access. All API endpoints require valid authentication.

### Configuration

```yaml
security:
  auth:
    type: session # session-based (cookie) auth
    session_timeout_hours: 24
    password_hash: "$2b$12$..." # bcrypt hash of password
    require_https: false # Can be false for localhost, true for network deployments
```

### Authentication Flow

1. **Initial Setup:** When the application first starts, the user sets a password.
2. **Login:** User provides password to get a session cookie.
3. **API Requests:** All requests include the session cookie or Bearer token.
4. **Session Expiry:** Sessions expire after 24 hours of inactivity.

### Session Management

Sessions are stored in SQLite:

```sql
CREATE TABLE auth_sessions (
    id TEXT PRIMARY KEY,
    password_hash TEXT NOT NULL,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    last_activity DATETIME DEFAULT CURRENT_TIMESTAMP,
    expires_at DATETIME NOT NULL
);
```

**Security:**

- Cookies are HttpOnly and Secure (HTTPS-only for network deployments)
- CSRF tokens on all state-changing endpoints (POST, PATCH, DELETE)
- Passwords hashed with bcrypt (cost factor 12)
- Sessions invalidated on logout

### API Authentication

All API endpoints (except `/api/auth/login` and `/api/health`) require authentication via one of:

**Option 1: Session Cookie (Web Browser)**

```
Cookie: session=abc123...
```

**Option 2: Bearer Token (CLI/SDK)**

```
Authorization: Bearer token_xyz...
```

Tokens are obtained via:

```
POST /api/auth/login
Body: { "password": "..." }
Response: { "token": "token_xyz...", "expires_in": 86400 }
```

---

## üê≥ Deployment

The application is packaged as a single, self-contained executable with all dependencies embedded. It supports both local development and network deployments.

### Option 1: Direct Download & Run

```bash
# Download the prebuilt binary
wget https://releases.lectures-app.io/lectures-latest-macos-arm64
chmod +x lectures-latest-macos-arm64

# Run it
./lectures-latest-macos-arm64

# Open browser to http://localhost:3000
# Set a password on first startup
```

**What's Included:**

- Backend compiled to native machine code
- Embedded SvelteKit frontend (pre-built static assets)
- SQLite (no external DB needed)
- Whisper model downloaded on first use

### Option 2: Docker (for consistency across machines)

```bash
docker run -p 3000:3000 -v ~/.lectures:/data lectures:latest
```

**docker-compose.yml:**

```yaml
version: "3.8"

services:
  lectures:
    image: ghcr.io/your-org/lectures:latest
    container_name: lectures-app
    ports:
      - "3000:3000"
    volumes:
      - lectures-data:/data
    environment:
      - DATA_DIRECTORY=/data
      - SERVER_PORT=3000
      - SERVER_HOST=0.0.0.0 # Listen on all interfaces inside container
      - LOG_LEVEL=info
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  lectures-data:
    driver: local
```

**Usage:**

```bash
docker-compose up -d
docker-compose logs -f
docker-compose down
```

### Dockerfile (Multi-Stage Build)

```dockerfile
# Stage 1: Build frontend (SvelteKit)
FROM node:20-alpine AS frontend-builder
WORKDIR /app/web
COPY web/package*.json ./
RUN npm ci
COPY web/ ./
RUN npm run build

# Stage 2: Build backend (Go)
FROM golang:1.22-alpine AS backend-builder
WORKDIR /app
COPY go.* ./
RUN go mod download
COPY . .
# Copy pre-built frontend from stage 1
COPY --from=frontend-builder /app/web/build ./web/build
RUN CGO_ENABLED=1 GOOS=linux go build -o lectures ./cmd/server

# Stage 3: Runtime image (minimal)
FROM alpine:3.19
RUN apk add --no-cache ca-certificates curl

# Copy binary
COPY --from=backend-builder /app/lectures /usr/local/bin/lectures

# Create data directory
RUN mkdir -p /data && chmod 777 /data

EXPOSE 3000
VOLUME ["/data"]
WORKDIR /data
ENTRYPOINT ["lectures"]
```

**Build & Push:**

```bash
docker build -t lectures:latest .
docker tag lectures:latest ghcr.io/your-org/lectures:latest
docker push ghcr.io/your-org/lectures:latest
```

### Network Deployment (Multi-User / Shared Server)

For shared server deployments with multiple users or network access:

```yaml
server:
  host: 0.0.0.0 # Listen on all interfaces
  port: 3000

security:
  require_https: true # Enforce HTTPS

storage:
  data_directory: /data # Use persistent volume


# Optional: Add reverse proxy (nginx) for:
#  - HTTPS termination
#  - Load balancing across multiple instances
#  - Rate limiting
```

**Docker Compose for network deployment:**

```yaml
services:
  lectures:
    image: ghcr.io/your-org/lectures:latest
    ports:
      - "127.0.0.1:3000:3000" # Bind to localhost, expose via nginx
    volumes:
      - lectures-data:/data
    environment:
      - SERVER_HOST=0.0.0.0
      - REQUIRE_HTTPS=true
    restart: unless-stopped

  nginx:
    image: nginx:latest
    ports:
      - "443:443"
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - /etc/letsencrypt:/etc/letsencrypt:ro
    depends_on:
      - lectures
```

---

## üì¶ Release Artifacts

Each release produces the following artifacts:

| Platform         | Format                             | Size   | Notes                                |
| ---------------- | ---------------------------------- | ------ | ------------------------------------ |
| macOS (Intel)    | `.dmg` + `.zip`                    | ~150MB | Code-signed and notarized            |
| macOS (ARM64)    | `.dmg` + `.zip`                    | ~150MB | Native Apple Silicon                 |
| Windows (x86_64) | `.exe` + `.zip`                    | ~160MB | Statically compiled, no dependencies |
| Linux (x86_64)   | `.tar.gz` + `.deb`                 | ~140MB | Also available on Package managers   |
| Linux (ARM64)    | `.tar.gz`                          | ~140MB | For Raspberry Pi, etc.               |
| Docker           | `ghcr.io/your-org/lectures:vX.Y.Z` | ~200MB | Pre-built multi-arch image           |

**Download Page:** `https://releases.lectures-app.io/`

---

## üöÄ Execution & Startup Flow

When the user runs the executable (or `docker run`), the following happens:

```
1. Parse configuration.yaml
   ‚îú‚îÄ If missing ‚Üí create defaults in ~/.lectures/
   ‚îî‚îÄ Log level, port, host, provider settings

2. Initialize SQLite database
   ‚îú‚îÄ If tables missing ‚Üí run schema.sql
   ‚îî‚îÄ Check integrity & version compatibility

3. Check authentication status
   ‚îú‚îÄ If no password set ‚Üí show setup screen
   ‚îÇ  ‚îî‚îÄ User creates password (stored as bcrypt hash)
   ‚îî‚îÄ If password exists ‚Üí ready for login

4. Load LLM Provider
   ‚îú‚îÄ Read llm.provider from config
   ‚îú‚îÄ Validate API key or local connection
   ‚îî‚îÄ If failed ‚Üí log warning, mark as unavailable

5. Load Transcription Provider
   ‚îú‚îÄ Check if Whisper is available
   ‚îú‚îÄ If not ‚Üí offer to download on first use
   ‚îî‚îÄ If offline mode ‚Üí skip

6. Start HTTP server
   ‚îú‚îÄ Bind to host:port
   ‚îú‚îÄ Register routes
   ‚îú‚îÄ Start job worker threads
   ‚îî‚îÄ Log: "Server running on http://localhost:3000"

7. Embed & serve frontend
   ‚îú‚îÄ All static assets pre-built into binary
   ‚îú‚îÄ No webpack dev server needed
   ‚îî‚îÄ Hot reload disabled in production

8. Launch browser (if possible)
   ‚îî‚îÄ Open http://localhost:3000

9. User authenticates (password or token)
   ‚îî‚îÄ Redirected to exam list and lecture management

10. User ready to create exams and upload lectures
```

---

## üìã Deployment Checklist

**Before first release:**

**Authentication & Authorization:**

- [ ] Password setup on first startup works
- [ ] Login/logout works (session creation & destruction)
- [ ] Unauthenticated requests rejected (401)
- [ ] Session expiry works (after timeout, re-login required)
- [ ] CSRF tokens validated on state-changing endpoints
- [ ] Bearer token authentication works (CLI/SDK access)

**API & Data:**

- [ ] All endpoints tested locally with authenticated requests
- [ ] Exam ‚Üí Lecture ‚Üí Media hierarchy enforced
- [ ] Slides/audio are required children of lectures
- [ ] Chat scoped to exam (can't access other exam's materials)
- [ ] WebSocket protocol tested (job progress & chat streaming)
- [ ] Database schema migrations tested (empty DB ‚Üí full state)

**File Operations:**

- [ ] File upload tested (small < 10MB, large >= 100MB, chunked)
- [ ] Multiple media uploads work (sequence order enforced)
- [ ] Reordering media files triggers transcript regeneration
- [ ] Deleting a media file regenerates transcript with remaining files
- [ ] Multiple reference document uploads work independently
- [ ] Document extraction works for PDF, PowerPoint, Word formats
- [ ] Transcript combines multiple media files with time offset adjustments
- [ ] Deletion cascades properly (exam ‚Üí lectures ‚Üí media ‚Üí transcript)

**AI Providers:**

- [ ] LLM provider integration tested (OpenRouter & Ollama)
- [ ] Transcription tested (Whisper model download & cache)
- [ ] PDF OCR processing tested (multi-page, complex layouts)
- [ ] Context assembly tested (token limits, truncation)

**Robustness:**

- [ ] Error scenarios tested (disk full, API down, invalid input)
- [ ] Large dataset performance tested (1000+ lectures, 500-page PDFs)
- [ ] Concurrent requests handled (multiple uploads, chats)
- [ ] Browser refresh during upload doesn't lose state

**Security:**

- [ ] No secrets in logs, no hardcoded keys
- [ ] Password hashing verified (bcrypt, not plaintext)
- [ ] Session cookies HttpOnly & Secure flags set
- [ ] HTTPS enforced in network deployments
- [ ] File permissions prevent cross-user access (single-user mode)

**Packaging:**

- [ ] Binary stripped of debug symbols (production build)
- [ ] Code signing & notarization (macOS)
- [ ] Installer created (Windows .msi, macOS .dmg)
- [ ] Docker images build and run correctly
- [ ] Embedded assets (frontend) included in binary

**Documentation:**

- [ ] User guide complete (setup, exams, lectures, chat)
- [ ] API documentation generated (endpoints, auth, errors)
- [ ] Database schema documented
- [ ] Troubleshooting guide written

---

Lastly, to make it perfectly packageable, the server is fully containerized and can be deployed via Docker, Docker Compose, or as a standalone executable.
